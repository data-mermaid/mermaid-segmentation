{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d37e781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload mode\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb19575",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34bd5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import mermaidseg.datasets.dataset\n",
    "import numpy as np\n",
    "from mermaidseg.io import setup_config, get_parser, update_config_with_args\n",
    "import copy\n",
    "import torch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d7931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Device 0: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "device_count = torch.cuda.device_count()\n",
    "for i in range(device_count):\n",
    "    print(f\"CUDA Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea3f30c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 06:36:37.965271: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-18 06:36:37.979140: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766039797.997780  128293 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766039798.003532  128293 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-18 06:36:38.021516: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from mermaidseg.model.meta import MetaModel\n",
    "from mermaidseg.model.eval import EvaluatorSemanticSegmentation\n",
    "from mermaidseg.logger import Logger\n",
    "from mermaidseg.model.train import train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43447f2d",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4e0786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start off with a configuration file\n",
    "cfg = setup_config(config_path='../configs/linear-dinov3-concept-bottleneck.yaml', config_base_path='../configs/concept_mermaid.yaml')\n",
    "\n",
    "# Update the initial configuration file with command line arguments \n",
    "# (in the case of a notebook run these can be defined explicitly here)\n",
    "args_input = \"--run-name=dinov3-test-concept-bottleneck-run_2 --batch-size=4 --epochs=5 --log-epochs=1\"\n",
    "args_input = args_input.split(\" \")\n",
    "\n",
    "parser = get_parser()\n",
    "args = parser.parse_args(args_input)\n",
    "\n",
    "cfg = update_config_with_args(cfg, args)\n",
    "cfg_logger = copy.deepcopy(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e7d85",
   "metadata": {},
   "source": [
    "# 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4144675",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = {}\n",
    "for split in cfg.augmentation:\n",
    "    transforms[split] = A.Compose(\n",
    "        [\n",
    "            getattr(A, transform_name)(**transform_params) for transform_name, transform_params\n",
    "                                                                 in cfg.augmentation[split].items()\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c0dad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = cfg.data.pop(\"name\", None)\n",
    "batch_size = cfg.data.pop(\"batch_size\", 4)\n",
    "whitelist_sources = cfg.data.pop(\"whitelist_sources\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "373143d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ffe178d-b1a9-4b06-9ef7-318a1c3ac46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict[\"train\"] = getattr(mermaidseg.datasets.dataset, dataset_name)(transform = transforms[split], **cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa72c11c-87ed-4e3f-aa21-e4a472a883e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8180"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_dict[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed349cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for split in [\"train\", \"val\", \"test\"]:\n",
    "#     dataset_dict[split] = getattr(mermaidseg.datasets.dataset, dataset_name)(transform = transforms[split], whitelist_sources=whitelist_sources[split], **cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd9cc3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for split in [\"train\", \"val\", \"test\"]:\n",
    "#     if split in dataset_dict:\n",
    "#         print(split, len(dataset_dict[split]), dataset_dict[split].num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14508e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize= (13,6), ncols = 2, nrows = 2)\n",
    "\n",
    "# image, mask, annotations = dataset[0]\n",
    "# print(image.shape, mask.shape)\n",
    "\n",
    "# ax[0, 0].imshow(image.transpose(1,2,0))\n",
    "# ax[0, 1].imshow(np.where(mask>0, mask, np.nan), cmap = \"tab10\", vmin=1, vmax=15)\n",
    "\n",
    "# image, mask, annotations = dataset[0]\n",
    "\n",
    "# ax[1, 0].imshow(image.transpose(1,2,0))\n",
    "# ax[1, 1].imshow(np.where(mask>0, mask, np.nan), cmap = \"tab10\", vmin=1, vmax=15)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a6aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(dataset_dict[\"train\"])\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset_dict[\"train\"], [train_size, val_size, test_size], generator=generator)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, range(5000))\n",
    "val_dataset = torch.utils.data.Subset(val_dataset, range(1000))\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, range(1000))\n",
    "# train_dataset = torch.utils.data.Subset(dataset_dict[\"train\"], range(3000))\n",
    "# val_dataset = torch.utils.data.Subset(dataset_dict[\"val\"], range(500))\n",
    "# test_dataset = torch.utils.data.Subset(dataset_dict[\"test\"], range(500))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True, collate_fn = dataset_dict[\"train\"].collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True, collate_fn = dataset_dict[\"train\"].collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True, collate_fn = dataset_dict[\"train\"].collate_fn)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True, collate_fn = dataset_dict[\"train\"].collate_fn)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True, collate_fn = dataset_dict[\"val\"].collate_fn)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True, collate_fn = dataset_dict[\"test\"].collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63fec21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 1250\n",
      "Number of validation batches: 250\n",
      "Number of test batches: 250\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of validation batches: {len(val_loader)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "382620c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict[\"train\"].num_classes, dataset_dict[\"train\"].num_concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f353f3a0",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b61ff27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = MetaModel(run_name = cfg.run_name, \n",
    "                       num_classes = dataset_dict[\"train\"].num_classes,\n",
    "                       num_concepts = dataset_dict[\"train\"].num_concepts,\n",
    "                       device = device,\n",
    "                       model_kwargs = cfg.model,\n",
    "                       training_mode = cfg.training_mode,\n",
    "                       training_kwargs = cfg.training,\n",
    "                       concept_matrix = dataset_dict[\"train\"].benthic_concept_matrix,\n",
    "                       conceptid2labelid = dataset_dict[\"train\"].conceptid2labelid,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c689a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EvaluatorSemanticSegmentation(num_classes=dataset_dict[\"train\"].num_classes,\n",
    "                                            device=device,\n",
    "                                            calculate_concept_metrics=True\n",
    "                                            )\n",
    "\n",
    "# from torchmetrics.classification import F1Score, JaccardIndex\n",
    "\n",
    "# metric_dict = {\n",
    "#             \"f1_class\": F1Score(task=\"multiclass\", average = \"none\", num_classes=3, ignore_index = 0).to(device),\n",
    "#             \"mean_iou\": JaccardIndex(task=\"multiclass\", num_classes=3, ignore_index = 0).to(device),\n",
    "#             \"iou\": JaccardIndex(task=\"multiclass\", num_classes=3, ignore_index = 0, average='none').to(device)\n",
    "#             }\n",
    "\n",
    "# evaluator = EvaluatorSemanticSegmentation(num_classes=dataset.num_concepts,\n",
    "#                                             device=device,\n",
    "#                                             metric_dict = metric_dict\n",
    "#                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc742a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mviktor-domazetoski\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sagemaker-user/mermaid-segmentation/nbs/wandb/run-20251218_063728-oe6a0nbl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/viktor-domazetoski/mermaid/runs/oe6a0nbl' target=\"_blank\">dinov3-test-concept-bottleneck-run_2</a></strong> to <a href='https://wandb.ai/viktor-domazetoski/mermaid' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/viktor-domazetoski/mermaid' target=\"_blank\">https://wandb.ai/viktor-domazetoski/mermaid</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/viktor-domazetoski/mermaid/runs/oe6a0nbl' target=\"_blank\">https://wandb.ai/viktor-domazetoski/mermaid/runs/oe6a0nbl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg.logger.experiment_name = \"mermaid\"\n",
    "cfg_logger.logger.experiment_name = \"mermaid\"\n",
    "\n",
    "from mermaidseg.logger import Logger\n",
    "\n",
    "logger = Logger(\n",
    "    config = cfg_logger,\n",
    "    meta_model = meta_model,\n",
    "    log_epochs = cfg.logger.log_epochs,\n",
    "    log_checkpoint = 2, #cfg.logger.log_checkpoint\n",
    "    checkpoint_dir = \".\",\n",
    "    enable_mlflow = False,\n",
    "    enable_wandb = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c28309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [20:18<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.3576062069684267\n",
      "TRAIN METRICS: {'accuracy': 0.9245154857635498, 'mean_iou': 0.7320473194122314, 'f1_concept': 0.8983958959579468}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 0 that is less than the current step 4. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "100%|██████████| 250/250 [03:26<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS valid 1.301874003648758\n",
      "VALID METRICS: {'accuracy': 0.6980696320533752, 'mean_iou': 0.44179531931877136, 'f1_concept': 0.6968477368354797}\n",
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 547/1250 [08:54<11:27,  1.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmermaidseg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_model\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mermaid-segmentation/mermaidseg/model/train.py:82\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(meta_model, evaluator, train_loader, val_loader, test_loader, logger, start_epoch, end_epoch, metric_of_interest)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m meta_model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 82\u001b[0m train_loss, train_metric_results \u001b[38;5;241m=\u001b[39m \u001b[43mmeta_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOSS train \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAIN METRICS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_metric_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mermaid-segmentation/mermaidseg/model/meta.py:307\u001b[0m, in \u001b[0;36mMetaModel.train_epoch\u001b[0;34m(self, train_loader, evaluator)\u001b[0m\n\u001b[1;32m    305\u001b[0m _, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    306\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 307\u001b[0m loss, outputs, concept_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_predict_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loss, torch\u001b[38;5;241m.\u001b[39mTensor), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss must be a torch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    310\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Double check\u001b[39;00m\n",
      "File \u001b[0;32m~/mermaid-segmentation/mermaidseg/model/meta.py:255\u001b[0m, in \u001b[0;36mMetaModel.batch_predict_loss\u001b[0;34m(self, batch, target_dim)\u001b[0m\n\u001b[1;32m    253\u001b[0m concept_outputs \u001b[38;5;241m=\u001b[39m segmentation_outputs\u001b[38;5;241m.\u001b[39mhidden_states\n\u001b[1;32m    254\u001b[0m outputs \u001b[38;5;241m=\u001b[39m segmentation_outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m--> 255\u001b[0m concept_labels \u001b[38;5;241m=\u001b[39m \u001b[43mlabels_to_concepts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcept_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(outputs, labels, concept_outputs, concept_labels)\n\u001b[1;32m    257\u001b[0m concept_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(concept_outputs)\n",
      "File \u001b[0;32m~/mermaid-segmentation/mermaidseg/datasets/concepts.py:241\u001b[0m, in \u001b[0;36mlabels_to_concepts\u001b[0;34m(labels, benthic_concept_matrix)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    240\u001b[0m     device \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 241\u001b[0m     labels_np \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m    242\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m lookup[labels_np]  \u001b[38;5;66;03m# shape (B, H, W, C)\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(mapped, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# (B, C, H, W)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mermaidseg.model.train import train_model\n",
    "train_model(meta_model, evaluator, train_loader, val_loader, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b770607-3bbc-4aa2-82ce-6aa20a4f3618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': MulticlassAccuracy(), 'mean_iou': MulticlassJaccardIndex()}\n",
      "{'f1_concept': MulticlassF1Score()}\n",
      "concept-bottleneck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:21<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "final_val_results = evaluator.evaluate_model(dataloader = val_loader, meta_model=meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "22e56b86-f47c-4663-9879-f3d050cab782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.700265645980835,\n",
       " 'mean_iou': 0.4505966901779175,\n",
       " 'f1_concept': array([0.       , 0.9828919, 0.6998219], dtype=float32)}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_val_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
